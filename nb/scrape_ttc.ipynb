{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Periodicals from The Talon Conspiracy\n",
    " \n",
    " This is a inteactive development notebook for building utilities to scrape periodicals from The Talon Conspiracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include Selenium as the core scraping utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  regular imports\n",
    "from utils.selenium_resource import SeleniumResource\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import (\n",
    "    StaleElementReferenceException,\n",
    "    TimeoutException,\n",
    "    NoSuchElementException,\n",
    ")\n",
    "from urllib.parse import urlparse\n",
    "from typing import List, Optional\n",
    "import logging\n",
    "import time\n",
    "from itertools import chain\n",
    "import pickle\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataclasses to store metadata and important dowload link targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class IssuuItem:\n",
    "    issuu_name: str\n",
    "    issuu_url: str\n",
    "    issuu_img_src: str\n",
    "    issuu_download_path: Optional[str] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TTCContent:\n",
    "    ttc_content_title: str\n",
    "    ttc_items: List[IssuuItem]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TTCTag:\n",
    "    \"The Talon Conpiracy - Items by Tag\"\n",
    "    ttc_accessible_name: str\n",
    "    ttc_tag_name: str\n",
    "    ttc_tag_url: str\n",
    "    # content is added after tag scrape\n",
    "    ttc_tag_content: Optional[List[TTCContent]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "\n",
    "def setup_logging(log_level=logging.INFO) -> logging.Logger:\n",
    "    \"\"\"\n",
    "    Configure logging to both file and console with rotation and formatting.\n",
    "\n",
    "    Args:\n",
    "        log_level: The logging level to use (default: logging.INFO)\n",
    "    \"\"\"\n",
    "    # Create logs directory if it doesn't exist\n",
    "    log_file = os.path.join(os.getcwd(), 'ttc_scrape.log')\n",
    "\n",
    "    # Create formatter\n",
    "    formatter = logging.Formatter(\n",
    "        '[%(asctime)s] %(levelname)s [%(name)s:%(lineno)s] %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "\n",
    "    # Configure root logger\n",
    "    root_logger = logging.getLogger()\n",
    "    root_logger.setLevel(log_level)\n",
    "\n",
    "    # Clear any existing handlers\n",
    "    root_logger.handlers = []\n",
    "\n",
    "    # Create rotating file handler (10MB max size, keep 5 backup files)\n",
    "    file_handler = RotatingFileHandler(\n",
    "        filename=log_file,\n",
    "        maxBytes=10*1024*1024,  # 10MB\n",
    "        backupCount=5,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    file_handler.setFormatter(formatter)\n",
    "    file_handler.setLevel(log_level)\n",
    "\n",
    "    # Create console handler\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setFormatter(formatter)\n",
    "    console_handler.setLevel(log_level)\n",
    "\n",
    "    # Add handlers to root logger\n",
    "    root_logger.addHandler(file_handler)\n",
    "    root_logger.addHandler(console_handler)\n",
    "\n",
    "    # Log system info at startup\n",
    "    logger = logging.getLogger(\"TTC Scrape Logger\")\n",
    "    logger.info('='*50)\n",
    "    logger.info(f'Logging initiated at {\n",
    "                datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    logger.info(f'Log file location: {log_file}')\n",
    "    logger.info('='*50)\n",
    "    return logger\n",
    "\n",
    "\n",
    "class WebScraper:\n",
    "    def __init__(self, max_retries: int = 3, timeout: int = 10):\n",
    "        self.max_retries = max_retries\n",
    "        self.timeout = timeout\n",
    "        self.logger = setup_logging()\n",
    "\n",
    "    def wait_and_find_element(\n",
    "            self,\n",
    "            driver,\n",
    "            by: By,\n",
    "            value: str,\n",
    "            timeout: Optional[int] = None,\n",
    "    ) -> Optional[any]:\n",
    "        \"\"\"Safely wait for and find an element with retries.\"\"\"\n",
    "        timeout = timeout or self.timeout\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                return WebDriverWait(driver, timeout).until(\n",
    "                    EC.presence_of_element_located((by, value))\n",
    "                )\n",
    "            except StaleElementReferenceException:\n",
    "                if attempt == self.max_retries - 1:\n",
    "                    raise\n",
    "                time.sleep(1)\n",
    "            except TimeoutException:\n",
    "                self.logger.warning(\n",
    "                    f\"Timeout waiting for element {by}={value}\")\n",
    "                return None\n",
    "\n",
    "    def wait_and_find_elements(\n",
    "        self,\n",
    "        driver,\n",
    "        by: By,\n",
    "        value: str,\n",
    "        timeout: Optional[int] = None,\n",
    "    ) -> List[any]:\n",
    "        \"\"\"Safely wait for and find elements with retries.\"\"\"\n",
    "        timeout = timeout or self.timeout\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                elements = WebDriverWait(driver, timeout).until(\n",
    "                    EC.presence_of_all_elements_located((by, value))\n",
    "                )\n",
    "                return elements\n",
    "            except StaleElementReferenceException:\n",
    "                if attempt == self.max_retries - 1:\n",
    "                    raise\n",
    "                time.sleep(1)\n",
    "            except TimeoutException:\n",
    "                self.logger.warning(\n",
    "                    f\"Timeout waiting for elements {by}={value}\")\n",
    "                return []\n",
    "\n",
    "    def get_attribute_safely(self, element, attribute: str) -> Optional[str]:\n",
    "        \"\"\"Safely get an attribute from an element with retries.\"\"\"\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                return element.get_attribute(attribute)\n",
    "            except StaleElementReferenceException:\n",
    "                if attempt == self.max_retries - 1:\n",
    "                    return None\n",
    "                time.sleep(1)\n",
    "\n",
    "    def click_download_button(\n",
    "        self,\n",
    "        driver,\n",
    "        timeout: Optional[int] = None,\n",
    "        wait_time: int = 5\n",
    "    ) -> bool:\n",
    "        \"\"\"\n",
    "        Click the download button with data-tooltip=\"Download\" and wait for download to complete.\n",
    "\n",
    "        Args:\n",
    "            driver: Selenium WebDriver instance\n",
    "            timeout: Optional timeout override (uses instance timeout if not specified)\n",
    "            wait_time: Time to wait after clicking for download to complete (default: 5 seconds)\n",
    "\n",
    "        Returns:\n",
    "            bool: True if download button was found and clicked successfully, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Find download button using data-tooltip attribute\n",
    "            download_button = self.wait_and_find_element(\n",
    "                driver,\n",
    "                By.CSS_SELECTOR,\n",
    "                '[data-tooltip=\"Download\"]',\n",
    "                timeout\n",
    "            )\n",
    "\n",
    "            if not download_button:\n",
    "                self.logger.warning(\"Download button not found\")\n",
    "                return False\n",
    "\n",
    "            # Check if button is clickable\n",
    "            if not download_button.is_enabled():\n",
    "                self.logger.warning(\"Download button is not enabled\")\n",
    "                return False\n",
    "\n",
    "            # Scroll button into view to ensure it's clickable\n",
    "            driver.execute_script(\n",
    "                \"arguments[0].scrollIntoView(true);\", download_button)\n",
    "            time.sleep(1)  # Brief pause after scrolling\n",
    "\n",
    "            # Click the download button\n",
    "            download_button.click()\n",
    "            self.logger.info(\"Download button clicked successfully\")\n",
    "\n",
    "            # Wait for specified time to allow download to complete\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error during download: {str(e)}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-04 00:07:41] INFO [TTC Scrape Logger:49] ==================================================\n",
      "[2024-12-04 00:07:41] INFO [TTC Scrape Logger:50] Logging initiated at 2024-12-04 00:07:41\n",
      "[2024-12-04 00:07:41] INFO [TTC Scrape Logger:52] Log file location: /app/nb/ttc_scrape.log\n",
      "[2024-12-04 00:07:41] INFO [TTC Scrape Logger:53] ==================================================\n",
      "[2024-12-04 00:08:01] INFO [TTC Scrape Logger:42] Found title for result FRONTLINE NEWS – THE COMPLETE SET!\n",
      "[2024-12-04 00:08:01] INFO [TTC Scrape Logger:42] Found title for result HISTORY AS IT WAS MADE: A TROVE OF ANTI-HUNTINGDON LIFE SCIENCES NEWSLETTERS.\n",
      "[2024-12-04 00:08:02] INFO [TTC Scrape Logger:42] Found title for result ANIMOSITY #3\n",
      "[2024-12-04 00:08:03] INFO [TTC Scrape Logger:42] Found title for result BITE BACK (U.K.) #1&2\n",
      "[2024-12-04 00:08:03] INFO [TTC Scrape Logger:42] Found title for result N.A.L.L. NEWSLETTERS – SUMMER AND SPRING 1985\n",
      "[2024-12-04 00:08:03] INFO [TTC Scrape Logger:42] Found title for result TURNING POINT #7-8\n",
      "[2024-12-04 00:08:03] INFO [TTC Scrape Logger:42] Found title for result EARTH FIRST! JOURNAL 1987\n",
      "[2024-12-04 00:08:03] INFO [TTC Scrape Logger:42] Found title for result WILD ROCKIES REVIEW VOL. 2 #1-2\n",
      "[2024-12-04 00:08:03] INFO [TTC Scrape Logger:42] Found title for result N.A.L.L. NEWSLETTER #7-8\n",
      "[2024-12-04 00:08:12] INFO [TTC Scrape Logger:42] Found title for result TURNING POINT #5-6\n",
      "[2024-12-04 00:08:13] INFO [TTC Scrape Logger:42] Found title for result SEAL #3\n",
      "[2024-12-04 00:08:13] INFO [TTC Scrape Logger:42] Found title for result COMBAT #2\n",
      "[2024-12-04 00:08:13] INFO [TTC Scrape Logger:42] Found title for result BLACK BEAST #1\n",
      "[2024-12-04 00:08:13] INFO [TTC Scrape Logger:42] Found title for result EARTH FIRST! JOURNAL 1980-1981\n",
      "[2024-12-04 00:08:13] INFO [TTC Scrape Logger:42] Found title for result ARKANGEL #10-11\n",
      "[2024-12-04 00:08:13] INFO [TTC Scrape Logger:42] Found title for result DO OR DIE – THE COMPLETE SET!\n",
      "[2024-12-04 00:08:13] INFO [TTC Scrape Logger:42] Found title for result BLACK BEAST #2-3\n",
      "[2024-12-04 00:08:13] INFO [TTC Scrape Logger:42] Found title for result BUAV LIBERATOR 1984\n",
      "[2024-12-04 00:08:13] INFO [TTC Scrape Logger:42] Found title for result X ULTRAMILITANCE X #2, 6\n",
      "[2024-12-04 00:08:25] INFO [TTC Scrape Logger:42] Found title for result S.A.R.P. NEWSLETTERS YEAR 3\n",
      "[2024-12-04 00:08:25] INFO [TTC Scrape Logger:42] Found title for result CLOSE HLS NEWSLETTERS\n",
      "[2024-12-04 00:08:25] INFO [TTC Scrape Logger:42] Found title for result SUPPORT ANIMAL RIGHTS PRISONERS NEWSLETTERS: YEAR TWO\n",
      "[2024-12-04 00:08:25] INFO [TTC Scrape Logger:42] Found title for result BUAV LIBERATOR – 1983\n",
      "[2024-12-04 00:08:26] INFO [TTC Scrape Logger:42] Found title for result THE SG NEWSLETTER, VOLUME 2.\n",
      "[2024-12-04 00:08:26] INFO [TTC Scrape Logger:42] Found title for result THE BEAST – RARE SUPPLEMENTAL ISSUES.\n",
      "[2024-12-04 00:08:26] INFO [TTC Scrape Logger:42] Found title for result SUPPORT ANIMAL RIGHTS PRISONERS NEWSLETTERS: YEAR ONE.\n",
      "[2024-12-04 00:08:26] INFO [TTC Scrape Logger:42] Found title for result DO OR DIE #10\n",
      "[2024-12-04 00:08:26] INFO [TTC Scrape Logger:42] Found title for result ALFSG DIARY OF ACTIONS #1-3\n",
      "[2024-12-04 00:08:26] INFO [TTC Scrape Logger:42] Found title for result THE HILLGROVE CAMPAIGN NEWSLETTER\n",
      "[2024-12-04 00:08:38] INFO [TTC Scrape Logger:42] Found title for result NO COMPROMISE: THE FINAL TWO ISSUES\n",
      "[2024-12-04 00:08:38] INFO [TTC Scrape Logger:42] Found title for result FLESH AND BLOOD\n",
      "[2024-12-04 00:08:39] INFO [TTC Scrape Logger:42] Found title for result ALF ACTION REPORTS\n",
      "[2024-12-04 00:08:39] INFO [TTC Scrape Logger:42] Found title for result DO OR DIE #9\n",
      "[2024-12-04 00:08:39] INFO [TTC Scrape Logger:42] Found title for result NO COMPROMISE #27-28\n",
      "[2024-12-04 00:08:39] INFO [TTC Scrape Logger:42] Found title for result THE VEGAN NEWS #1\n",
      "[2024-12-04 00:08:39] INFO [TTC Scrape Logger:42] Found title for result THE ALF SUPPORTERS GROUP NEWSLETTER – THE COMPLETE ORIGINAL SET!\n",
      "[2024-12-04 00:08:39] INFO [TTC Scrape Logger:42] Found title for result NO COMPROMISE #23-26\n",
      "[2024-12-04 00:08:39] INFO [TTC Scrape Logger:42] Found title for result ARKANGEL 8-9\n",
      "[2024-12-04 00:08:40] INFO [TTC Scrape Logger:42] Found title for result NO COMPROMISE #20-22\n",
      "[2024-12-04 00:08:53] INFO [TTC Scrape Logger:42] Found title for result LIBERATE!\n",
      "[2024-12-04 00:08:54] INFO [TTC Scrape Logger:42] Found title for result FRONTLINE NEWS #1\n",
      "[2024-12-04 00:08:54] INFO [TTC Scrape Logger:42] Found title for result NO COMPROMISE #18-19\n",
      "[2024-12-04 00:08:54] INFO [TTC Scrape Logger:42] Found title for result ANIMAL INFO\n",
      "[2024-12-04 00:08:54] INFO [TTC Scrape Logger:42] Found title for result FACKLAN\n",
      "[2024-12-04 00:08:54] INFO [TTC Scrape Logger:42] Found title for result DO OR DIE #8\n",
      "[2024-12-04 00:08:54] INFO [TTC Scrape Logger:42] Found title for result EARTH FIRST! JOURNAL 1986\n",
      "[2024-12-04 00:08:54] INFO [TTC Scrape Logger:42] Found title for result LOMAKATSI\n",
      "[2024-12-04 00:08:54] INFO [TTC Scrape Logger:42] Found title for result NO COMPROMISE #15-17\n",
      "[2024-12-04 00:08:54] INFO [TTC Scrape Logger:42] Found title for result SHAC REVISITED\n",
      "[2024-12-04 00:09:05] INFO [TTC Scrape Logger:42] Found title for result DO OR DIE #1,3,4\n",
      "[2024-12-04 00:09:05] INFO [TTC Scrape Logger:42] Found title for result NO COMPROMISE #12-14\n",
      "[2024-12-04 00:09:05] INFO [TTC Scrape Logger:42] Found title for result THE BEAST #1-#10\n",
      "[2024-12-04 00:09:05] INFO [TTC Scrape Logger:42] Found title for result WHEN THE NATIONALS WERE RADICAL, PART 1\n",
      "[2024-12-04 00:09:05] INFO [TTC Scrape Logger:42] Found title for result DESPERATELY SEEKING OLD NEWSLETTERS!\n",
      "[2024-12-04 00:09:05] INFO [TTC Scrape Logger:42] Found title for result DO OR DIE #7\n",
      "[2024-12-04 00:09:05] INFO [TTC Scrape Logger:42] Found title for result SPIRIT OF FREEDOM: THE NEWSLETTER OF THE NORTH AMERICAN EARTH LIBERATION PRISONER SUPPORT NETWORK\n",
      "[2024-12-04 00:09:05] INFO [TTC Scrape Logger:42] Found title for result THINGS WE ARE NOT ALLOWED TO SHOW YOU, PART 1\n",
      "[2024-12-04 00:09:06] INFO [TTC Scrape Logger:42] Found title for result ARKANGEL #4,5,7\n",
      "[2024-12-04 00:09:06] INFO [TTC Scrape Logger:42] Found title for result UNDERGROUND #17\n",
      "[2024-12-04 00:09:13] INFO [TTC Scrape Logger:42] Found title for result BREAKING FREE VIDEO MAGAZINE #2\n",
      "[2024-12-04 00:09:13] WARNING [TTC Scrape Logger:50] No links with images\n",
      "[2024-12-04 00:09:13] INFO [TTC Scrape Logger:42] Found title for result NO COMPROMISE #9, 10, 11\n",
      "[2024-12-04 00:09:13] INFO [TTC Scrape Logger:42] Found title for result X ULTRA-MILITANCE X #1, 3-5\n",
      "[2024-12-04 00:09:13] INFO [TTC Scrape Logger:42] Found title for result BREAKING FREE VIDEO MAGAZINE #1\n",
      "[2024-12-04 00:09:13] WARNING [TTC Scrape Logger:50] No links with images\n",
      "[2024-12-04 00:09:13] INFO [TTC Scrape Logger:42] Found title for result NO COMPROMISE #8 / STRATEGIC NON-VIOLENCE FOR ANIMAL LIBERATION\n",
      "[2024-12-04 00:09:13] INFO [TTC Scrape Logger:42] Found title for result FRONTLINE #3-4\n",
      "[2024-12-04 00:09:14] INFO [TTC Scrape Logger:42] Found title for result DO OR DIE #6\n",
      "[2024-12-04 00:09:14] INFO [TTC Scrape Logger:42] Found title for result THIS IS THE A.L.F.\n",
      "[2024-12-04 00:09:14] INFO [TTC Scrape Logger:42] Found title for result HOW TO SPEAK AUSTRALIAN\n",
      "[2024-12-04 00:09:14] INFO [TTC Scrape Logger:42] Found title for result NO COMPROMISE #6-7\n",
      "[2024-12-04 00:09:21] INFO [TTC Scrape Logger:42] Found title for result SOUTH EAST LIBERATOR\n",
      "[2024-12-04 00:09:22] INFO [TTC Scrape Logger:42] Found title for result ECO-VEGAN\n",
      "[2024-12-04 00:09:22] INFO [TTC Scrape Logger:42] Found title for result BITE BACK #6-10\n",
      "[2024-12-04 00:09:22] INFO [TTC Scrape Logger:42] Found title for result THE ANIMAL LIBERATION FRONT SUPPORTERS GROUP NEWSLETTER #17\n",
      "[2024-12-04 00:09:22] INFO [TTC Scrape Logger:42] Found title for result COMBAT #1\n",
      "[2024-12-04 00:09:22] INFO [TTC Scrape Logger:42] Found title for result DO OR DIE #5\n",
      "[2024-12-04 00:09:22] INFO [TTC Scrape Logger:42] Found title for result UNDERGROUND #16\n",
      "[2024-12-04 00:09:22] INFO [TTC Scrape Logger:42] Found title for result UNDERGROUND #14-15\n",
      "[2024-12-04 00:09:22] INFO [TTC Scrape Logger:42] Found title for result UNDERGROUND #10-13\n",
      "[2024-12-04 00:09:22] INFO [TTC Scrape Logger:42] Found title for result UNDERGROUND #7-9\n",
      "[2024-12-04 00:09:30] INFO [TTC Scrape Logger:42] Found title for result UNDERGROUND #4-6\n",
      "[2024-12-04 00:09:30] INFO [TTC Scrape Logger:42] Found title for result HOLOCAUST #4\n",
      "[2024-12-04 00:09:30] INFO [TTC Scrape Logger:42] Found title for result OUT OF THE CAGES #6-9\n",
      "[2024-12-04 00:09:30] INFO [TTC Scrape Logger:42] Found title for result LIVE WILD OR DIE #1-3\n",
      "[2024-12-04 00:09:30] INFO [TTC Scrape Logger:42] Found title for result RESISTANCE\n",
      "[2024-12-04 00:09:30] INFO [TTC Scrape Logger:42] Found title for result NO COMPROMISE #1-5\n",
      "[2024-12-04 00:09:30] INFO [TTC Scrape Logger:42] Found title for result STATE OF THE MOVEMENT\n",
      "[2024-12-04 00:09:30] INFO [TTC Scrape Logger:42] Found title for result STRONGHEARTS\n",
      "[2024-12-04 00:09:30] INFO [TTC Scrape Logger:42] Found title for result UNDERGROUND #1-3\n",
      "[2024-12-04 00:09:30] INFO [TTC Scrape Logger:42] Found title for result THE MILITANT VEGAN\n",
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:42] Found title for result ARKANGEL #1-3\n",
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:42] Found title for result SPECTACULAR TIMES #10: ANIMALS\n",
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:42] Found title for result BITE BACK #1-5\n",
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:42] Found title for result DRESSED IN BLACK\n",
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:42] Found title for result UK ALF SUPPORTERS GROUP NEWSLETTER BARRY HORNE TRIBUTE ISSUE\n",
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:42] Found title for result MEMPHIS VEGAN #5\n",
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:42] Found title for result DO NOT CONSIDER YOURSELF FREE\n",
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:42] Found title for result CONTENTION BUILDER\n",
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:42] Found title for result EAT ME\n"
     ]
    }
   ],
   "source": [
    "def scrape_ttc_by_periodical_content(\n",
    "    url: str,\n",
    "    client=SeleniumResource(),\n",
    "    scraper=WebScraper(),\n",
    ") -> TTCContent:\n",
    "    try:\n",
    "\n",
    "        client.setup_for_execution()\n",
    "        driver = client.driver\n",
    "        # Navigate to tag page\n",
    "\n",
    "        driver.get(url)\n",
    "\n",
    "        # Get content results\n",
    "        content_results = scraper.wait_and_find_elements(\n",
    "            driver,\n",
    "            By.CLASS_NAME,\n",
    "            \"results_content\"\n",
    "        )\n",
    "\n",
    "        ttc_content = []\n",
    "        for result in content_results:\n",
    "            try:\n",
    "                # Get the Category type. Include only periodicals.\n",
    "\n",
    "                category_labels = [category.text for category in result.find_elements(\n",
    "                    By.CSS_SELECTOR,\n",
    "                    \"h3 a[rel]\"\n",
    "                )]\n",
    "\n",
    "                if \"PERIODICALS\" not in category_labels:\n",
    "                    continue\n",
    "\n",
    "                # Get title from the current result element\n",
    "                result_title = result.find_element(By.TAG_NAME, \"h1\")\n",
    "                if not result_title:\n",
    "                    scraper.logger.warning(\n",
    "                        \"No title found for content result\")\n",
    "                    continue\n",
    "\n",
    "                title_text = result_title.text\n",
    "                scraper.logger.info(f\"Found title for result {title_text}\")\n",
    "\n",
    "                # Get links with images\n",
    "                links_with_images = result.find_elements(\n",
    "                    By.CSS_SELECTOR,\n",
    "                    \"a:has(img)\",\n",
    "                )\n",
    "                if not links_with_images:\n",
    "                    scraper.logger.warning(\"No links with images\")\n",
    "                    continue\n",
    "\n",
    "                ttc_issuus = []\n",
    "                for link_img in links_with_images:\n",
    "                    issuu_href = scraper.get_attribute_safely(\n",
    "                        link_img, \"href\")\n",
    "                    img_element = link_img.find_element(\n",
    "                        By.TAG_NAME,\n",
    "                        \"img\",\n",
    "                    )\n",
    "                    if not img_element:\n",
    "                        continue\n",
    "\n",
    "                    issuu_img_src = scraper.get_attribute_safely(\n",
    "                        img_element, \"src\")\n",
    "                    if not issuu_href or not issuu_img_src:\n",
    "                        continue\n",
    "\n",
    "                    issu_name = urlparse(issuu_img_src).path.strip(\n",
    "                        \"/\").split(\"/\")[-1]\n",
    "                    issuu_item = IssuuItem(\n",
    "                        issuu_name=issu_name,\n",
    "                        issuu_url=issuu_href,\n",
    "                        issuu_img_src=issuu_img_src\n",
    "                    )\n",
    "                    ttc_issuus.append(issuu_item)\n",
    "\n",
    "                ttc_content_result = TTCContent(\n",
    "                    ttc_content_title=result_title.text,\n",
    "                    ttc_items=ttc_issuus.copy()\n",
    "                )\n",
    "                ttc_content.append(ttc_content_result)\n",
    "\n",
    "            except StaleElementReferenceException:\n",
    "                continue\n",
    "            except NoSuchElementException:\n",
    "                logging.warning(\"Missing h1 tag in result.\")\n",
    "                continue\n",
    "            except StaleElementReferenceException:\n",
    "                logging.warning(\n",
    "                    \"Result became stale, skipping\")\n",
    "                continue\n",
    "        return ttc_content\n",
    "    except Exception as e:\n",
    "        scraper.logger.error(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "    finally:\n",
    "        client.teardown_after_execution()\n",
    "\n",
    "\n",
    "###################\n",
    "periodical_urls = [f\"https://thetalonconspiracy.com/category/periodicals/page/{\n",
    "    page_num}/\"for page_num in range(1, 11)]\n",
    "\n",
    "# Unnest\n",
    "periodicals = list(chain(*[scrape_ttc_by_periodical_content(\n",
    "    url) for url in periodical_urls]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:49] ==================================================\n",
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:50] Logging initiated at 2024-12-04 00:09:39\n",
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:52] Log file location: /app/nb/ttc_scrape.log\n",
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:53] ==================================================\n"
     ]
    }
   ],
   "source": [
    "def download_content_issuus(\n",
    "    content: TTCContent,\n",
    "    client=SeleniumResource(),\n",
    "    scraper=WebScraper(),\n",
    "):\n",
    "    try:\n",
    "        client.setup_for_execution()\n",
    "        driver = client.driver\n",
    "        # Navigate to tag page\n",
    "\n",
    "        driver.get()\n",
    "    except Exception as e:\n",
    "        scraper.logger.error(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "    finally:\n",
    "        client.teardown_after_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:49] ==================================================\n",
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:50] Logging initiated at 2024-12-04 00:09:39\n",
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:52] Log file location: /app/nb/ttc_scrape.log\n",
      "[2024-12-04 00:09:39] INFO [TTC Scrape Logger:53] ==================================================\n"
     ]
    }
   ],
   "source": [
    "def download_content_issuus(\n",
    "    content=TTCContent,\n",
    "    client=SeleniumResource(),\n",
    "    scaper=WebScraper()\n",
    "\n",
    ")-> TTCContent:\n",
    "    x = 1\n",
    "\n",
    "\n",
    "#####\n",
    "download_content_issuus(\n",
    "    content=periodicals[0]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

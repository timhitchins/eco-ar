{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Periodicals from The Talon Conspiracy\n",
    " \n",
    " This is a inteactive development notebook for building utilities to scrape periodicals from The Talon Conspiracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include Selenium as the core scraping utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  regular imports\n",
    "from utils.selenium_resource import SeleniumResource\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import (\n",
    "    StaleElementReferenceException,\n",
    "    TimeoutException,\n",
    "    NoSuchElementException,\n",
    ")\n",
    "from urllib.parse import urlparse\n",
    "from typing import List, Optional\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataclasses to store metadata and important dowload link targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class IssuuItem:\n",
    "    issuu_name: str\n",
    "    issuu_url: str\n",
    "    issuu_img_src: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TTCContent:\n",
    "    ttc_content_title: str\n",
    "    ttc_items: List[IssuuItem]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TTCTag:\n",
    "    \"The Talon Conpiracy - Items by Tag\"\n",
    "    ttc_accessible_name: str\n",
    "    ttc_tag_name: str\n",
    "    ttc_tag_url: str\n",
    "    # content is added after tag scrape\n",
    "    ttc_tag_content: Optional[List[TTCContent]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-27 06:56:30] INFO [TTC Scrape Logger:49] ==================================================\n",
      "[2024-11-27 06:56:30] INFO [TTC Scrape Logger:50] Logging initiated at 2024-11-27 06:56:30\n",
      "[2024-11-27 06:56:30] INFO [TTC Scrape Logger:52] Log file location: /app/nb/ttc_scrape.log\n",
      "[2024-11-27 06:56:30] INFO [TTC Scrape Logger:53] ==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "\n",
    "def setup_logging(log_level=logging.INFO) -> logging.Logger:\n",
    "    \"\"\"\n",
    "    Configure logging to both file and console with rotation and formatting.\n",
    "\n",
    "    Args:\n",
    "        log_level: The logging level to use (default: logging.INFO)\n",
    "    \"\"\"\n",
    "    # Create logs directory if it doesn't exist\n",
    "    log_file = os.path.join(os.getcwd(), 'ttc_scrape.log')\n",
    "\n",
    "    # Create formatter\n",
    "    formatter = logging.Formatter(\n",
    "        '[%(asctime)s] %(levelname)s [%(name)s:%(lineno)s] %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "\n",
    "    # Configure root logger\n",
    "    root_logger = logging.getLogger()\n",
    "    root_logger.setLevel(log_level)\n",
    "\n",
    "    # Clear any existing handlers\n",
    "    root_logger.handlers = []\n",
    "\n",
    "    # Create rotating file handler (10MB max size, keep 5 backup files)\n",
    "    file_handler = RotatingFileHandler(\n",
    "        filename=log_file,\n",
    "        maxBytes=10*1024*1024,  # 10MB\n",
    "        backupCount=5,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    file_handler.setFormatter(formatter)\n",
    "    file_handler.setLevel(log_level)\n",
    "\n",
    "    # Create console handler\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setFormatter(formatter)\n",
    "    console_handler.setLevel(log_level)\n",
    "\n",
    "    # Add handlers to root logger\n",
    "    root_logger.addHandler(file_handler)\n",
    "    root_logger.addHandler(console_handler)\n",
    "\n",
    "    # Log system info at startup\n",
    "    logger = logging.getLogger(\"TTC Scrape Logger\")\n",
    "    logger.info('='*50)\n",
    "    logger.info(f'Logging initiated at {\n",
    "                datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    logger.info(f'Log file location: {log_file}')\n",
    "    logger.info('='*50)\n",
    "    return logger\n",
    "\n",
    "\n",
    "class WebScraper:\n",
    "    def __init__(self, max_retries: int = 3, timeout: int = 10):\n",
    "        self.max_retries = max_retries\n",
    "        self.timeout = timeout\n",
    "        self.logger = setup_logging()\n",
    "\n",
    "    def wait_and_find_element(\n",
    "            self,\n",
    "            driver,\n",
    "            by: By,\n",
    "            value: str,\n",
    "            timeout: Optional[int] = None,\n",
    "    ) -> Optional[any]:\n",
    "        \"\"\"Safely wait for and find an element with retries.\"\"\"\n",
    "        timeout = timeout or self.timeout\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                return WebDriverWait(driver, timeout).until(\n",
    "                    EC.presence_of_element_located((by, value))\n",
    "                )\n",
    "            except StaleElementReferenceException:\n",
    "                if attempt == self.max_retries - 1:\n",
    "                    raise\n",
    "                time.sleep(1)\n",
    "            except TimeoutException:\n",
    "                self.logger.warning(\n",
    "                    f\"Timeout waiting for element {by}={value}\")\n",
    "                return None\n",
    "\n",
    "    def wait_and_find_elements(\n",
    "        self,\n",
    "        driver,\n",
    "        by: By,\n",
    "        value: str,\n",
    "        timeout: Optional[int] = None,\n",
    "    ) -> List[any]:\n",
    "        \"\"\"Safely wait for and find elements with retries.\"\"\"\n",
    "        timeout = timeout or self.timeout\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                elements = WebDriverWait(driver, timeout).until(\n",
    "                    EC.presence_of_all_elements_located((by, value))\n",
    "                )\n",
    "                return elements\n",
    "            except StaleElementReferenceException:\n",
    "                if attempt == self.max_retries - 1:\n",
    "                    raise\n",
    "                time.sleep(1)\n",
    "            except TimeoutException:\n",
    "                self.logger.warning(\n",
    "                    f\"Timeout waiting for elements {by}={value}\")\n",
    "                return []\n",
    "\n",
    "    def get_attribute_safely(self, element, attribute: str) -> Optional[str]:\n",
    "        \"\"\"Safely get an attribute from an element with retries.\"\"\"\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                return element.get_attribute(attribute)\n",
    "            except StaleElementReferenceException:\n",
    "                if attempt == self.max_retries - 1:\n",
    "                    return None\n",
    "                time.sleep(1)\n",
    "\n",
    "\n",
    "def scrape_ttc_tags(\n",
    "        ttc_url=\"https://thetalonconspiracy.com/\",\n",
    "        client=SeleniumResource(),\n",
    "        scraper=WebScraper(),\n",
    "        ttc_tags=[],\n",
    ") -> List[TTCTag]:\n",
    "\n",
    "    try:\n",
    "        client.setup_for_execution()\n",
    "        driver = client.driver\n",
    "        driver.get(ttc_url)\n",
    "\n",
    "        # Wait for sidebar and get links\n",
    "        sidebar_tag_links = scraper.wait_and_find_elements(\n",
    "            driver,\n",
    "            By.XPATH,\n",
    "            \"//div[@id='sidebarleft']//li//a[@href]\"\n",
    "        )\n",
    "\n",
    "        # Main scraping loop\n",
    "        ttc_tags = []\n",
    "        while True:\n",
    "\n",
    "            # Process each tag link\n",
    "            for link in sidebar_tag_links:\n",
    "                ttc_accessible_name = link.accessible_name\n",
    "                ttc_tag_url = scraper.get_attribute_safely(link, 'href')\n",
    "                if not ttc_tag_url:\n",
    "                    continue\n",
    "\n",
    "                parsed_url = urlparse(ttc_tag_url).path\n",
    "                ttc_tag_name = parsed_url.strip(\"/\").split(\"/\")[-1]\n",
    "                ttc_tags.append(\n",
    "                    TTCTag(\n",
    "                        ttc_accessible_name=ttc_accessible_name,\n",
    "                        ttc_tag_name=ttc_tag_name,\n",
    "                        ttc_tag_url=ttc_tag_url,\n",
    "                        ttc_tag_content=None, # added later\n",
    "                    )\n",
    "                )\n",
    "            break  # Exit the main loop after processing all tags\n",
    "        scraper.logger.info(\"Scraping TTC Tags complete.\")\n",
    "        return ttc_tags\n",
    "\n",
    "    except Exception as e:\n",
    "        scraper.logger.error(f\"An error occurred: {str(e)}\")\n",
    "        return []\n",
    "    finally:\n",
    "        client.teardown_after_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-27 06:56:56] INFO [TTC Scrape Logger:162] Scraping TTC Tags complete.\n"
     ]
    }
   ],
   "source": [
    "ttc_tags = scrape_ttc_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-27 07:56:29] INFO [TTC Scrape Logger:49] ==================================================\n",
      "[2024-11-27 07:56:29] INFO [TTC Scrape Logger:50] Logging initiated at 2024-11-27 07:56:29\n",
      "[2024-11-27 07:56:29] INFO [TTC Scrape Logger:52] Log file location: /app/nb/ttc_scrape.log\n",
      "[2024-11-27 07:56:29] INFO [TTC Scrape Logger:53] ==================================================\n",
      "[2024-11-27 07:56:29] INFO [TTC Scrape Logger:7] Scraping content from tag: '\"The Mysterious Joseph\"'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 107\u001b[0m\n\u001b[1;32m    103\u001b[0m         client\u001b[38;5;241m.\u001b[39mteardown_after_execution()\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m############################################\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m ttc_content \u001b[38;5;241m=\u001b[39m [\u001b[43mscrape_ttc_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m ttc_tags]\n",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m, in \u001b[0;36mscrape_ttc_content\u001b[0;34m(ttc_tag, client, scraper)\u001b[0m\n\u001b[1;32m     12\u001b[0m driver \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mdriver\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Navigate to tag page\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mttc_tag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mttc_tag_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Get content results\u001b[39;00m\n\u001b[1;32m     18\u001b[0m content_results \u001b[38;5;241m=\u001b[39m scraper\u001b[38;5;241m.\u001b[39mwait_and_find_elements(\n\u001b[1;32m     19\u001b[0m     driver,\n\u001b[1;32m     20\u001b[0m     By\u001b[38;5;241m.\u001b[39mCLASS_NAME,\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults_content\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:389\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:378\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m    376\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m--> 378\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/selenium/webdriver/remote/remote_connection.py:391\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    389\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[1;32m    390\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/selenium/webdriver/remote/remote_connection.py:415\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    412\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 415\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/urllib3/_request_methods.py:143\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m    136\u001b[0m         method,\n\u001b[1;32m    137\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/urllib3/_request_methods.py:278\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[1;32m    276\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/urllib3/poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def scrape_ttc_content(\n",
    "    ttc_tag: TTCTag,\n",
    "    client=SeleniumResource(),\n",
    "    scraper=WebScraper(),\n",
    ") -> TTCTag:\n",
    "    try:\n",
    "        scraper.logger.info(\n",
    "            f\"Scraping content from tag: {\n",
    "                ttc_tag.ttc_accessible_name!r}\")\n",
    "\n",
    "        client.setup_for_execution()\n",
    "        driver = client.driver\n",
    "        # Navigate to tag page\n",
    "\n",
    "        driver.get(ttc_tag.ttc_tag_url)\n",
    "\n",
    "        # Get content results\n",
    "        content_results = scraper.wait_and_find_elements(\n",
    "            driver,\n",
    "            By.CLASS_NAME,\n",
    "            \"results_content\"\n",
    "        )\n",
    "\n",
    "        ttc_content = []\n",
    "        for result in content_results:\n",
    "            try:\n",
    "                # Get the Category type. Include only periodicals.\n",
    "\n",
    "                category_labels = [category.text for category in result.find_elements(\n",
    "                    By.CSS_SELECTOR,\n",
    "                    \"h3 a[rel]\"\n",
    "                )]\n",
    "\n",
    "                if \"PERIODICALS\" not in category_labels:\n",
    "                    continue\n",
    "\n",
    "                # Get title from the current result element\n",
    "                result_title = result.find_element(By.TAG_NAME, \"h1\")\n",
    "                if not result_title:\n",
    "                    scraper.logger.warning(\n",
    "                        \"No title found for content result\")\n",
    "                    continue\n",
    "\n",
    "                title_text = result_title.text\n",
    "                scraper.logger.info(f\"Found title for result {title_text}\")\n",
    "\n",
    "                # Get links with images\n",
    "                links_with_images = result.find_elements(\n",
    "                    By.CSS_SELECTOR,\n",
    "                    \"a:has(img)\",\n",
    "                )\n",
    "                if not links_with_images:\n",
    "                    scraper.logger.warning(\"No links with images\")\n",
    "                    continue\n",
    "\n",
    "                ttc_issuus = []\n",
    "                for link_img in links_with_images:\n",
    "                    issuu_href = scraper.get_attribute_safely(\n",
    "                        link_img, \"href\")\n",
    "                    img_element = link_img.find_element(\n",
    "                        By.TAG_NAME,\n",
    "                        \"img\",\n",
    "                    )\n",
    "                    if not img_element:\n",
    "                        continue\n",
    "\n",
    "                    issuu_img_src = scraper.get_attribute_safely(\n",
    "                        img_element, \"src\")\n",
    "                    if not issuu_href or not issuu_img_src:\n",
    "                        continue\n",
    "\n",
    "                    issu_name = urlparse(issuu_img_src).path.strip(\n",
    "                        \"/\").split(\"/\")[-1]\n",
    "                    issuu_item = IssuuItem(\n",
    "                        issuu_name=issu_name,\n",
    "                        issuu_url=issuu_href,\n",
    "                        issuu_img_src=issuu_img_src\n",
    "                    )\n",
    "                    ttc_issuus.append(issuu_item)\n",
    "\n",
    "                ttc_content_result = TTCContent(\n",
    "                    ttc_content_title=result_title.text,\n",
    "                    ttc_items=ttc_issuus.copy()\n",
    "                )\n",
    "                ttc_content.append(ttc_content_result)\n",
    "\n",
    "            except StaleElementReferenceException:\n",
    "                continue\n",
    "            except NoSuchElementException:\n",
    "                logging.warning(\"Missing h1 tag in result.\")\n",
    "                continue\n",
    "            except StaleElementReferenceException:\n",
    "                logging.warning(\n",
    "                    \"Result became stale, skipping\")\n",
    "                continue\n",
    "            ttc_tag.ttc_tag_content = ttc_content\n",
    "            return ttc_tag\n",
    "    except Exception as e:\n",
    "        scraper.logger.error(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "    finally:\n",
    "        client.teardown_after_execution()\n",
    "\n",
    "\n",
    "############################################\n",
    "ttc_content = [scrape_ttc_content(tag) for tag in ttc_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
